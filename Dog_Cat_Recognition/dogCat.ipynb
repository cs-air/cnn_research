{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dog photos from the dogs vs cats dataset\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "# plot first few images\n",
    "for i in range(16):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(4,4,i+1)\n",
    "\t# define filename\n",
    "\tfilename = folder + 'dog.' + str(i) + '.jpg'\n",
    "\t# load image pixels\n",
    "\timage = imread(filename)\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PHOTO PRE-PROCESSOR\"\"\"\n",
    "\n",
    "\"\"\"ONLY USE IF YOU HAVE MORE THAN 12 GB RAM\"\"\"\n",
    "\n",
    "\n",
    "# # load dogs vs cats dataset, reshape and save to a new file\n",
    "# from os import listdir\n",
    "# from numpy import asarray\n",
    "# from numpy import save\n",
    "# from keras.preprocessing.image import load_img\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "# # define location of dataset\n",
    "# folder = 'train/'\n",
    "# photos, labels = list(), list()\n",
    "# # enumerate files in the directory\n",
    "# for file in listdir(folder):\n",
    "# \t# determine class\n",
    "# \toutput = 0.0\n",
    "# \tif file.startswith('cat'):\n",
    "# \t\toutput = 1.0\n",
    "# \t# load image\n",
    "# \tphoto = load_img(folder + file, target_size=(200, 200))\n",
    "# \t# convert to numpy array\n",
    "# \tphoto = img_to_array(photo)\n",
    "# \t# store\n",
    "# \tphotos.append(photo)\n",
    "# \tlabels.append(output)\n",
    "# # convert to a numpy arrays\n",
    "# photos = asarray(photos)\n",
    "# labels = asarray(labels)\n",
    "# print(photos.shape, labels.shape)\n",
    "# # save the reshaped photos\n",
    "# save('dogs_vs_cats_photos.npy', photos)\n",
    "# save('dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PHOTO PRE-PROCESSOR TEST\"\"\"\n",
    "\n",
    "# # load and confirm the shape\n",
    "# from numpy import load\n",
    "# photos = load('dogs_vs_cats_photos.npy')\n",
    "# labels = load('dogs_vs_cats_labels.npy')\n",
    "# print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"ALTERNATE PHOTO PRE-PROCESSOR\"\"\"\n",
    "\n",
    "\n",
    "# # organize dataset into a useful structure\n",
    "# from os import makedirs\n",
    "# from os import listdir\n",
    "# from shutil import copyfile\n",
    "# from random import seed\n",
    "# from random import random\n",
    "\n",
    "\n",
    "# # create directories\n",
    "# dataset_home = 'dataset_dogs_vs_cats/'\n",
    "# subdirs = ['train/', 'test/']\n",
    "# for subdir in subdirs:\n",
    "# \t# create label subdirectories\n",
    "# \tlabeldirs = ['dogs/', 'cats/']\n",
    "# \tfor labldir in labeldirs:\n",
    "# \t\tnewdir = dataset_home + subdir + labldir\n",
    "# \t\tmakedirs(newdir, exist_ok=True)\n",
    "\n",
    "# # seed random number generator\n",
    "# seed(1)\n",
    "# # define ratio of pictures to use for validation\n",
    "# val_ratio = 0.25\n",
    "# # copy training dataset images into subdirectories\n",
    "# src_directory = 'train/'\n",
    "# for file in listdir(src_directory):\n",
    "# \tsrc = src_directory + '/' + file\n",
    "# \tdst_dir = 'train/'\n",
    "# \tif random() < val_ratio:\n",
    "# \t\tdst_dir = 'test/'\n",
    "# \tif file.startswith('cat'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
    "# \t\tcopyfile(src, dst)\n",
    "# \telif file.startswith('dog'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "# \t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# baseline model with data augmentation for the dogs vs cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ONE BLOCK VGG MODEL\"\"\"\n",
    "\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" TWO BLOCK VGG MODEL\"\"\"\n",
    "\n",
    "\n",
    "# # define cnn model\n",
    "# def define_model():\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# \tmodel.add(Dense(1, activation='sigmoid'))\n",
    "# \t# compile model\n",
    "# \topt = SGD(lr=0.001, momentum=0.9)\n",
    "# \tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# \treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" THREE BLOCK VGG MODEL\"\"\"\n",
    "\n",
    "\n",
    "# # define cnn model\n",
    "# def define_model():\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# \tmodel.add(Dense(1, activation='sigmoid'))\n",
    "# \t# compile model\n",
    "# \topt = SGD(lr=0.001, momentum=0.9)\n",
    "# \tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# \treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" FOUR BLOCK VGG MODEL\"\"\"\n",
    "\n",
    "\n",
    "# # define cnn model\n",
    "# def define_model():\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "#     #4th block\n",
    "#     model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# \tmodel.add(Dense(1, activation='sigmoid'))\n",
    "# \t# compile model\n",
    "# \topt = SGD(lr=0.001, momentum=0.9)\n",
    "# \tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# \treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" FIFTH BLOCK VGG MODEL\"\"\"\n",
    "\n",
    "\n",
    "# # define cnn model\n",
    "# def define_model():\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "#     #4th block\n",
    "#     model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "#     #5th block\n",
    "#     model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# \tmodel.add(Dense(1, activation='sigmoid'))\n",
    "# \t# compile model\n",
    "# \topt = SGD(lr=0.001, momentum=0.9)\n",
    "# \tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# \treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" SIX BLOCK VGG MODEL\"\"\"\n",
    "\n",
    "\n",
    "# # define cnn model\n",
    "# def define_model():\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "# \tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "\t\n",
    "# \t#4th block\n",
    "# \tmodel.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# \t#5th block\n",
    "# \tmodel.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# \t#6th block\n",
    "# \tmodel.add(Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "# \tmodel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "# \tmodel.add(Dense(1, activation='sigmoid'))\n",
    "# \t# compile model\n",
    "# \topt = SGD(lr=0.001, momentum=0.9)\n",
    "# \tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# \treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(211)\n",
    "\tpyplot.title('Cross Entropy Loss')\n",
    "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\t# plot accuracy\n",
    "\tpyplot.subplot(212)\n",
    "\tpyplot.title('\\nClassification Accuracy')\n",
    "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\t# save plot to file\n",
    "\tfilename = sys.argv[0].split('/')[-1]\n",
    "\tprint(f\"\\n\\n{filename}\\n\\n\")\n",
    "\tpyplot.savefig(filename + '_plot.png')\n",
    "\tpyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "\tmodel = define_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('dataset_dogs_vs_cats/train/',\n",
    "\t\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('dataset_dogs_vs_cats/test/',\n",
    "\t\t\tclass_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "\t# fit model        \n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=1)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 288 images belonging to 2 classes.\nFound 72 images belonging to 2 classes.\nEpoch 1/1\n"
    },
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[64,32,200,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_15/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics_4/accuracy/Identity/_489]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[64,32,200,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_15/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ac6c88879450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# entry point, run the test harness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrun_test_harness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-12ab44b0512f>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n\u001b[1;32m---> 14\u001b[1;33m \t\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=1, verbose=1)\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dog_cat\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dog_cat\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dog_cat\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dog_cat\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dog_cat\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dog_cat\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[64,32,200,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_15/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics_4/accuracy/Identity/_489]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[64,32,200,200] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node conv2d_15/convolution}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num GPUs Available:  1\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitdogcatcondad5cb6844368341b0a2e74f09a26de54b",
   "display_name": "Python 3.7.6 64-bit ('dog_cat': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}